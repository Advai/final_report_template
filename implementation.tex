\section{Implementation}
\label{sec:implementation}
As noted earlier since the implementation of flexible quorum is trivial and not dependent on Chained Raft, it will not be covered here. 
The base of our implementation is forked from eraft, an open source generic raft library written in C++ linked in the appendix. 
We had to make changes to the structure of the specification for the Chained raft implementation to remain feasible. 
Following from the Chained Raft specification detailed prior, we have included additional information about the divergence of the specification from the implementation we utimately ended up using.

\subsection{Block Markers}
One of the main building blocks of Chained Raft is the idea of a block marker. 
The term marker is supposed to be analogous to a pointer, but in the case of a non-shared memory system (like a distributed system) this is quite an over-simplification. 
Thus, the main cost in changing from a mutable structured log entry to a immutable chain of blocks is the added overhead of finding equivalence for a atomic unit (block or entry). 
Indexes are no longer used, so we need to verify location as well as data to check for equivalence.
To satisfy the safety property of consensus, we need to ensure there is no chance that a mis-equivalence will occur. 
This would cost us to have to walk the whole chain behind a block everytime, as each blocks identity is dependant on the blocks (chain) before it. 


As a result, we propose the idea of giving up the absolute guarantee of safety, for a probabilistic guarantee. 
In practice we believe this tradeoff will allow the safety property to always hold true (although not provably), whilst still allowing the performance and observability gains that can result from the immutability changes to the log structure. 
We have seen other consensus algorithms (namely, PoW in Bitcoin\cite{nakamoto2012bitcoin}) utilize a similar tradeoff in practice, to massive practical success and safety.
By attaching a $64$ bit unsigned integer id to each block (generated by some pseudo random number generator), we can show that the probability of a mis-equivalence of two blocks is on the order of $\frac{1}{2}^{64}$. 
Under workloads with a large variety of unique commands, we can show much further reductions as we use id and command data for an equivalence check of two blocks. 
Furthermore, keeping track of all ids of blocks in active chains (any chain extending the commit block) allows the leader to ensure that no two blocks will be active with the same id.
The only way this can break is if one leader generates the same id as the very next leader does. 
If the next leader does not see this id (less than $\frac{1}{2}$ nodes received the block) they may call a SendAppendRPC with an block with the same id that extends a different block. 
This would eventually lead to a safety violation. During our validation testing and benchmarking we were not able to observe such behavior, and think it would require network partitions or fail-stop restart faults.
We should note that this tradeoff is implementation specific. 
In practice, we saw that nodes weren't noticeably slowed down when using true block chain validation. Thus, we abstract away whether or not the implementation uses true safety or probabilistic in the following sections.

\subsection{Leader Commits}
Without Chained blocks, the leader typically selects the $n/2$ highest match index (flexible quorum) of all its peers to be its updated commit index during a commit. 
With blocks, we change match index to “match offsets”, where offsets refer to the closest block behind the head that the current peer has matched. 
The leader takes the $n/2$ lowest match offset as the potential new commit offset. The leader uses these offset to walk back from its head marker and update its commit block (if its a newer block). 
In other words, the leader then updates the commit block to the furthest block (longest-chain) that at least $n/2$ peers have matched. 
As a result of using offsets now, the leader needs to update the offsets every time its head marker moves.

\subsection{Fork Garbage Collection}
Upon an update of the commit marker, we can safely garbage collect any chains that no longer extend the commit block. 
Consequently, we call all chains that extend the commit block active as they still are needed for program execution. 
To garbage collect old forks, we keep track of all the active heads and their tails (the closest block on the commit chain) in a hash-map.
Upon every update to the commit marker, we then garbage collect chains that are newly found "dead" (no longer extending the new commit block).
This naturally allows the hash-map of alive chains to remain up to date and usable for it's intended searching purposes. 
We invoke garbage collection every update of the commit block, thus it is important to update the hash-map upon changes to the block chain.  

\subsection{Log Compaction}
Our log compaction does not change from regular Raft. During compaction, we simply delete all blocks that are correspondingly being compacted from the block chain.
Then we set the block which extends the persisted block to extend the genesis block (cut the tail).
During update of commit marker, we convert block entries to regular log entries and keep our committed log state to be that of a regular raft log. This way we keep the immutability of the log while keeping the same
interface for existing log compaction and entry persistance api's.