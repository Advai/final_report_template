\section{Implementation}
\label{sec:implementation}
As noted earlier the implementation of Flexible Raft is trivial and will not be covered here. 
The base of our implementation is forked from eraft, an open source generic raft library written in C++. 
We heavily changed the structure of the implementation for our chained raft implementation, which can be viewed in the repository linked below. 
Following from the Chained Raft specification detailed prior, we have included additional information about the divergence of the specification from the implementation we chose.

\subsection{Block Markers}
    One of the main building blocks of Chained Raft is the idea of a block marker. 
The term marker is supposed to be analogous to a pointer, but in the case of a non-shared memory system (like a distributed system) this is quite an over-simplification. 
Mainly, we cannot check the equivalence of blocks by serializing the local virtual addresses in which they are stored, as there is no guarantee that each process is storing the blocks at the same address.
    The main cost in changing from a structured log entry to a chain of blocks is from finding equivalence of entries. 
    If we take the naive approach and just use commands to check equivalence of blocks, we can run into a violation of safety by falsely claiming two blocks as equal. 
    Yet if we are too cautious, we will have to walk (and thus also send) the whole chain of blocks preceding the block in order to guarantee equivalence. 
        As a result, we propose the idea of giving up the absolute guarantee of safety, for a probabilistic guarantee. 
        In practice we believe this tradeoff will allow safety to always hold true (although not provably), whilst still allowing the performance and observability gains that can result from the immutability changes to the log structure. 
        We have seen other consensus algorithms (namely, PoW in Bitcoin\cite{nakamoto2012bitcoin}) utilize a similar tradeoff in practice.
  
The idea is as follows: if we attach a $64$ bit integer id to each block (generated by some pseudo random number generator), we can show that the probability of a mis-equivalence of two blocks is on the order of $\frac{1}{2}^{64}$. 
Under workloads with a large variety of commands, we can show further reductions if we use comparison of block id, command type, and command in our equivalence check of two blocks. 
Lastly, we have a rough idea of how one could carefully implement such a system to ensure that the same $64$ bit integer would have to be generated twice in a row (order of $\frac{1}{2}^{128}$).
    
    Thus, we claim that in practice this probability should never be violated if we are careful. 
    Mainly, we can store a local hash-map at each node keeping track of the ids in use. 
    Once blocks have been committed (i.e the commit marker now extends the block), garbage-collected, or persisted, we can remove their id from the local map. 
    When the leader then generates a new id for a new block they can ensure a unique id. 
    This further reduces the chance at a collision. 
    One may actually be able to show a formal proof that if we follow the above correctly, we can ensure that for a misclassification to occur, we have provided a rough idea in the appendix. 
    The rest of our subsections build upon this idea of block equivalence. 
    Thus, we abstract away whether or not the implementation uses true safety or probabilistic.

\subsection{Leader Commits}
Without chained blocks, the leader typically selects the $n/2$ highest match index (flexible quorum) of all its peers to be its updated commit index during a commit. 
With blocks, we change match index to “match offsets”, where offsets refer to the blocks behind the head that the current peer is. 
Now, as we take the $n/2$ lowest match offset, The leader uses this offset to walk back from its head marker and update its commit block. 
In other words, the leader then updates the commit block to the furthest block (longest-chain) that at least $n/2$ peers have found equivalence to.

\subsection{Fork Garbage Collection}
Upon an update of the commit marker, we can safely garbage collect any chains that no longer extend the commit block. 
To do this, we need to keep track of all the heads of each side chain of the block-chain using a vector of block pointers. 
The implementation of such is quite simple. 
We invoke garbage collection every update of the commit block, thus it is important to keep an accurate vector of chain heads. 

\subsection{Log Compaction}
Lastly we wanted to note that we were not able to implement Chained Raft log compaction fully as of now. 
Instead, we will outline our plan for implementing compaction. 
Just like the original paper, Chained Raft will use snapshots for log compaction. 
Since blocks will be used to store a bulk of commands, we expect that snapshots will be taken less often and make log compaction. 
Storing snapshots will require walking a chain of block pointers, which will be less memory-effective as walking a contiguous block of memory.  
This project is still in progress for another week and a half, so we cannot speak for performance at this time.